---
title: "R Notebook"
output:
  pdf_document: default
---
# SYS 6021 Group Project 1

# Accident Damage
## Hypothesis 1 (Lea Jih-Vieira)
### Setup
```{r setup}
library(ggplot2)
library(psych)
library(magrittr)
library(dplyr)
library(lattice)
library(here)
library(ggpubr)
library(ggfortify)
library(MASS)
library(lindia)

source("/Users/leajih-vieira/Downloads/UVA Grad/SYS 6021/AccidentInput.R")

options(scipen = 999)
```

### (1) Generating Hypotheses:
For the first hypothesis, we wanted to explore if common accident causes have any relationship with the amount of damage that occurs. From our outside research, we found that some of the most common causes of train accidents include human error, high speed trains, derailments, and unprotected railroad crossings [(Gilreath & Associates)](https://www.sidgilreath.com/railroad-accidents-causes.html). Knowing that these are some of the most common causes of train accidents, this gives us sufficient reason to study their relationship with accident damage costs. As per project instructions, we are studying only accidents with damages above the upper whisker, so we are also studying if the most common causes of train accidents result in accidents with high damages due to this filtering.

Null Hypothesis: Human error, crossing-related, high-speed, derailment accidents do not have a statistically significant relationship with accident damage costs.

Alternative Hypothesis: Human error, crossing-related, high-speed, derailment accidents have a statistically significant relationship with accident damage costs. 

#### Exploratory Analysis

Load the train data and filter for ACCDMG values above the upper whisker.
```{r results = 'hide', fig.keep = "none"}
pathname <- "/Users/leajih-vieira/Downloads/UVA Grad/SYS 6021/Train Data"
acts <- file.inputl(pathname)

sapply(acts, dim)
totacts <- combine.data(acts)

dmgbox <-boxplot(totacts$ACCDMG)

xdmg <- totacts[totacts$ACCDMG > dmgbox$stats[5],]

## Remove 9/11
xdmg <- xdmg[-181,]

# Remove duplicates from xdmg and call new data frame xdmgnd
xdmgnd <- xdmg[!(duplicated(xdmg[, c("INCDTNO", "YEAR", "MONTH", "DAY", 
                                     "TIMEHR", "TIMEMIN")])),]

## Reset rownames
rownames(xdmgnd) <- NULL
```
For our analysis of Hypothesis 1, we need to create three new binary columns: hError, crossing, and derail.

- hError: Indicates whether or not the primary cause of the accident was human error (0: No, 1: Yes)

- crossing: Indicates whether or not the accident occurred at a highway-rail or railroad grade crossing (0: No, 1: Yes)

- derail: Indicates whether or not the accident was a derailment (0: No, 1: Yes)

One thing to note regarding our use of railroad crossing data is that our data is potentially inaccurate in representing unprotected railroad crossings as we discussed in our research phase. As we mentioned earlier, our background research identified unprotected railroad crossings as a common cause of train accidents; however, our dataset does not contain information regarding unprotected railroad crossings. Instead, our dataset only provides information about highway-rail crossings and railroad grade crossings, while also posessing a code for "other" types of accidents (but no further detail on the "other" column). Highway-rail crossings and railroad grade crossings are known to have more signage and safety measures in place compared to unprotected crossings, which typically only have stop signs and do not possess gates [(LA Times)](https://www.latimes.com/archives/la-xpm-2000-sep-17-me-22577-story.html). However, we felt that since we still had data on some kinds of crossing-related accidents, it would still be informative to study this relationship. We do not have information as to what exact safety precautions were in place at the crossings in our dataset, as some may have had more in place than others, so we determined it would still be a useful to investigate.
```{r}
# hError
xdmgnd$hError <- 0

for (i in 1:nrow(xdmgnd)) {
  code <- substr(xdmgnd[i, "CAUSE"], 1, 1)
  
  if (code == "H") {
    xdmgnd[i, "hError"] <- 1
  }
}

# crossing
xdmgnd$crossing <- 0

for (i in 1:nrow(xdmgnd)) {
  # Hwy-rail crossing or RR Grade Crossing
  xdmgnd[i, "crossing"] <- xdmgnd$TYPE[i] == 7 || xdmgnd$TYPE[i] == 8 
}

# derail
xdmgnd$derail <- 0

for (i in 1:nrow(xdmgnd)) {
  xdmgnd[i, "derail"] <- xdmgnd$TYPE[i] == 1 # Derailment
}
```
The only predictor variable that we did not need to create or transform was train speed, our only continuous predictor for Hypothesis 1.

Next, we conducted some exploratory analysis of our predictor variables via visualizations and summary statistics to get a sense of how our model may look.
```{r}
# hError
ggplot(xdmgnd, aes(x = as.factor(hError))) +
  geom_bar(fill= "cyan4") + 
  ggtitle("Bar Chart of Human Error vs Non-Human Error Related Accidents") + 
  labs(y= "Count", x = "Primary Cause of Accident") + 
  scale_x_discrete(labels=c("Non-Human Error", "Human Error"))

# crossing
ggplot(xdmgnd, aes(x = as.factor(crossing))) +
  geom_bar(fill= "cyan4") + 
  ggtitle("Bar Chart of Crossing vs Non-Crossing Related Accidents") + 
  labs(y= "Count", x = "Type of Accident") + 
  scale_x_discrete(labels=c("Non-Crossing", "Crossing"))

# derail
ggplot(xdmgnd, aes(x = as.factor(derail))) +
  geom_bar(fill= "cyan4") + 
  ggtitle("Bar Chart of Derailment vs Non-Derailment Related Accidents") + 
  labs(y= "Count", x = "Type of Accident") + 
  scale_x_discrete(labels=c("Non-Derailment", "Derailment"))
```
First we looked at bar charts of each of the binary predictor variables to get a sense of the frequency of each variable. For each predictor, it does appear to lean heavily in one direction vs the other, but still appears to have sufficient representation of both groups for most of the binary variables. Human error accidents are less frequent than non-human error accidents, but human error accidents still make up ~25% of the dataset. Derailments are more frequent than non-derailments, indicating that derailments may tend to incur high damage costs.

The only variable that seems to have less representation is crossing, as there is a noticeably lower frequency of crossing-related accidents compared to non-crossing. This observation could be indicative of the fact that there are not many crossing related accidents that incur high damage costs, since we are only looking at the subset of accidents above the upper whisker. Perhaps there are many more crossing-related accidents that are below the upper whisker threshold, but are excluded from our dataset due to our filtering guidelines. This highly skewed distribution of crossing-related accidents should not affect the model, and we have identified reason(s) why this skewedness makes sense in the context of this situation, but it is still important to draw attention to and keep in mind as we develop our regression model [(Cross Validated)](https://stats.stackexchange.com/questions/370017/binary-predictor-with-highly-skewed-distribution).

For our single continuous variable, train speed, we can make observations about how it interacts with damage costs by making a scatter plot of the two.
```{r}
ggplot(xdmgnd, aes(x= ACCDMG, y= TRNSPD)) + 
  geom_point(color= "cyan4", alpha = 0.4) +
  ggtitle("Scatterplot of Accident Damage vs Train Speed") + 
  labs(y= "Train Speed (MPH)", x = "Accident Damage (Dollars)") + 
  scale_x_continuous(labels = scales::dollar_format())
```
As we can observe from the figure above, most of the data is gathered on the left side of the plot, indicating that many of the accidents incur around the same damage costs regardless of the train speed. However, we do see a weak positive trend as we move left to right, showing that accident damages loosely seem to increase as train speed increases. Part of what is difficult about reading this figure is that the accident damage amounts are so spread out, with the majority of the data gathered on the left side of the graph. We can adjust our x-axis upper limit to get a better look at the behavior of the majority of the data, excluding the outliers.
```{r}
ggplot(xdmgnd, aes(x= ACCDMG, y= TRNSPD)) + 
  geom_point(color= "cyan4", alpha = 0.4) +
  ggtitle("Scatterplot of Accident Damage vs Train Speed (Limited to $10 Million") + 
  labs(y= "Train Speed (MPH)", x = "Accident Damage (Dollars)") + 
  scale_x_continuous(labels = scales::dollar_format()) + # FIX
  xlim(0, 10000000)
```
From this plot we can observe the interaction between accident damage and train speed in more detail. We can see more clearly here that the two have a positive linear relationship where accident damages tend to increase as train speed increases.

The last component of our exploratory analysis of Hypothesis 1 was to look at the Pearson correlation matrix to observe the variable correlations. In this case it does not make sense to plot a scatterplot matrix because most of the predictor variables are binary.
```{r}
cor(xdmgnd[ , c("ACCDMG", "hError", "crossing", "derail", "TRNSPD")], method= "pearson")
```
From this correlation matrix, we can see that train speed has the highest absolute correlation with accident damage with a correlation of 0.249. The other binary variables do not seem to have a high correlation with the outcome variable, which may indicate that our predictors will have limited inferential power of accident damages. However, we decided to move forward with building a full model with all four predictors to see what it looked like to then adjust accordingly after analyzing the initial model.

As per project instructions, we can only consider quantitative variables if they interact with a qualitative one. We chose to interact derailments with train speed, as they both seem to have the most strong relationship with accident damages.

### (2) Analysis
Our first model was a full main effects model with one interaction between derailments and train speed.
```{r}
xdmgnd.main <- lm(ACCDMG ~ hError + crossing + derail*TRNSPD, data= xdmgnd)

summary(xdmgnd.main)
```
Above is the summary of our main effects model for Hypothesis 1. The intercept is equal to 557084, meaning that when a train accident is not caused by human error, not a crossing-related accident, and not a derailment, the accident damage cost is $557,084. Human error, train speed, and the interaction between derailment and train speed have positive coefficients, meaning that damage costs increase if the binary variables are true and/or train speed increases. Crossing-related accidents and derailments have a negative relationship with damage costs, meaning that damage costs decrease if these terms are true. All of the parameters are significant at the p < 0.001 level.

The biggest downside to our main effects model is that it only has an adjusted R-squared value of 0.075. This means that our model explains very little of the variance of accident damage. Without even looking at other performance metrics like AIC or BIC, we decided to try alternative models since the R-squared value is so poor. We decided to start the improvement process by building a second order model that includes all pairwise interaction terms to see if the model improves at all.
```{r}
xdmgnd.inter <- lm(ACCDMG ~ (hError + crossing + derail*TRNSPD)^2, 
                   data= xdmgnd)

summary(xdmgnd.inter)
```
Above is the summary of our second model that includes all of the pairwise interaction terms. The interaction model's intercept is 683004.1, meaning that when a train accident is not caused by human error, not a crossing-related accident, and not a derailment, the accident damage cost is $683,004.10. In comparison to the main effects model, the intercept of the interaction model is higher. Human error, crossing-related accidents, derailments, the interaction between crossing-related accidents and train speed, and the interaction between human error, derailment, and train speed all have negative relationships with accident damage due to their negative coefficient values. Alternatively, train speed and the remaining interaction coefficients are positive. Seven out of the eleven parameters are significant at the p < 0.05 level.

Our adjusted R-squared value only improved by 0.0255, making the improvement from the main effects model to the interactions model quite small. In a final effort to try and find a better model, we chose to conduct a stepwise regression to see what the algorithm would choose as the best predictors. 
```{r}
xdmgnd.inter.step <- step(xdmgnd.inter, trace= F)

summary(xdmgnd.inter.step)
```
Above is the final stepwise regression model. Out of the ten coefficients available from the interaction model, the stepwise model chose nine of them. The only term left out was the interaction term between crossing-related accidents and train speed, probably because it had the highest p-value of all the coefficients in the interaction model. All of the parameters are significant at the p < 0.05 level except for crossing-related accidents.

The stepwise model produced the highest adjusted R-squared value at 0.1003, but this is still only a 0.0001 improvement from the full interaction model, making this improvement almost negligible.

Before finalizing the model, we also need to check the diagnostics plots to identify if linear regression assumptions are satsfied and if we need to make any transformations or adjustments.
```{r}
autoplot(xdmgnd.inter.step, which=1, label.size = 3) + theme_bw()
```
The residuals vs fitted plot is used to test for a constant mean of 0 and constant variance. The lack of a constant mean of 0 is expected here because our model is not a good fit for the data with such a low adjusted R-squared value. We can also see that the variance is not homoscedastic. 
```{r}
autoplot(xdmgnd.inter.step, which=2, label.size = 3) + theme_bw()
```
The QQ plot is used to look for close alignment with the quantiles of a normal distribution. Here we can see that the QQ plot violates the assumption and displays heavy-tailed behavior. The QQ plot combined with the heteroscedastic variance indicates to us that we should transform the response variable.
```{r}
autoplot(xdmgnd.inter.step, which=4, label.size = 3) + theme_bw()
```
Cook's distance is used to identify influential points in the dataset for our model. Here we can see that there are two points above 0.5, making them notably influential and indicating to us that we should remove them.

After analyzing the diagnostics plots, we identified that we need to transform the response variable and remove two influential points. First we will remove the two influential points.
```{r}
cooks.rm <- c(5251, 5956)

xdmgnd.rm <- xdmgnd[-cooks.rm, ]

rownames(xdmgnd.rm) <- NULL
```
After removing the two influential points, we ran a boxcox plot to identify how we should transform accident damage.
```{r}
boxcox(xdmgnd.inter.step)
```
From the boxcox plot above, we can see that the brackets are between -1 and 0. This means that we should perform a boxcox transformation with the optimal lambda value.
```{r}
# Optimal lambda
xval <- which.max(boxcox(xdmgnd.inter.step, plotit = F)$y)
lam <- boxcox(xdmgnd.inter.step, plotit = F)$x[xval] 

# Run the new interaction regression model with the transformation
xdmgnd.inter.boxcox <- lm((ACCDMG^lam-1)/lam ~ (hError + crossing + derail*TRNSPD)^2, 
                          data= xdmgnd.rm)

# Run a stepwise regression with the new interaction model
xdmgnd.inter.step.boxcox <- step(xdmgnd.inter.boxcox, trace= F)

summary(xdmgnd.inter.step.boxcox)
```
Above is the final stepwise interaction model after removing influential points and performing a boxcox transformation. Similar to the first stepwise interaction model, the only term left out of this model is the interaction term between crossing-related accidents and train speed. Seven of the ten coefficients are signficant at the p < 0.001 level, showing less overall significance among the predictors compared to the previous model. However, looking at the adjusted R-squared value we can see that we have obtained our highest value yet at 0.183, which is 0.083 higher than the model before we made adjustments. Additionally, we have an f-statistic with a p-value < 0.001, indicating that the model is significant.
```{r}
autoplot(xdmgnd.inter.step.boxcox, which=c(1, 2, 4), label.size = 3) + theme_bw()
```
We can also take another look at the diagnostics plots above. After performing a boxcox transformation and removing the two influential points, we can see that our diagnostics plots look much better than before the adjustments. The residual vs fitted plot has a more constant mean of 0 and more homoscedasticity than the previous model. The QQ plot displays more linear behavior than the previous model, and the Cook's distance values are all below 0.09.

While the model has improved a lot compared to previous iterations, there are certainly still problems present with the model. The first is that the adjusted R-squared value, while improved, is still quite low. Despite the low f-statistic p-value indicating that the model is statistically significant, the low adjusted R-squared value makes us very skeptical that this model has much predictive or inferential power. Additionally, while the variance improved from the adjustments we made, it still displays some heteroscedastic behavior and therefore still violates the constant variance assumption. Violating this assumption also makes us skeptical of the model's power since lack of constant variance affects the precision of the model. In addition, heteroscedasticity tends to produce p-values that are deceptively significant, which may be misleading us to think that the model and its coefficients are more signficant than they actually are [(Statistics by Jim)](https://statisticsbyjim.com/regression/heteroscedasticity-regression/). 

### (4) Evidence & Recommendation to FRA

#### Conclusion

Based on our findings above, we fail to reject the null hypothesis. Despite the model producing a significant f-statistic p-value (p-value < 0.00000000000000022), our violation of the constant variance assumption leads us to believe our model is not reliable enough to reject the null hypothesis. Our low adjusted R-squared value of 0.183 also supports this conclusion.

#### Recommendations

The purpose of Hypothesis 1 was to study the relationship between common train accident causes and the level of accident damages with the intention of providing the FRA with recommendations to improve railroad safety. Based on our findings, we have found that human-error, crossing-related, high-speed, and derailment accidents do not have a statistically significant impact on accident damage costs. Some of these factors such as train speed and derailments showed potential to influence accident damage more, but we could not gather enough evidence to definitively support that claim. Perhaps the common train accident causes studied in this project result in more low-cost accidents, but that relationship was not studied due to our filtering for accident damages above the upper whisker.

We recommend to investigate alternative factors to improve railroad safety as per the FRA's primary goal, but we also believe some of these factors should still be monitored for their potential significance in the future.